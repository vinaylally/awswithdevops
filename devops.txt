paths:
cd /var/www/html ------httpd path for index.html




tomcat:
chkconfig httpd on
tomcat is an opensource java based web application server.
tomcat apache 
jboss 
yum install java-11* -y
alternatives --config java
webapps/manager/META-INF/context.xml
conf/tomcat-users.xml
conf/server.xml
bin/startup.sh
bin/shutdown.sh
 1  cd /opt
    2  yum install java-11* -y
    3  yum install git -y
    4  yum install maven
#    5  wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.88/bin/apache-tomcat-9.0.88.zip
    6  wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.88/bin/apache-tomcat-9.0.88.zip
    7  ls
    8  unzip apache-tomcat-9.0.88.zip
    9  cd /opt
   10  ls
   11  cd apache-tomcat-9.0.88/
   12  ls
   13  cd bin/
   14  ls
   15  chmod u+x *.sh
   16  ls
   17  cd ..
 # 18  ln -s /opt/apache-tomcat-9.0.88/bin/startup.sh /usr/bin/startTomcat
 # 19  ln -s /opt/apache-tomcat-9.0.88/bin/shutdown.sh /usr/bin/stopTomcat

===============================================================
what is maven?
open source javabased build tool.it supports only java code.
standalone app .jar
web app .war
enterprise app .ear
maven local repo
maven central repo
maven remote repo nexus
validate
compile 
test
package
after that target folder created automatically 
yum install java-1.8* -y
mvn clean packege
https://docs.aws.amazon.com/neptune/latest/userguide/iam-auth-connect-prerq.html --link for download java 1.8
===================================================================
ansible:
sudo apt update
sudo apt install software-properties-common
sudo apt-add-repository --yes --update ppa:ansible/ansible
sudo apt install ansible


inventory file:/etc/ansible/hosts
config file: /etc/ansible/ansible.cfg
executable location: /usr/bin/ansible
which ansible
sudo passwd ubuntu
sudo vim /etc/ssh/sshd_config
 sudo service ssh restart
sudo ssh-keygen
ssh-copy-id ubuntu@private ip
ansible -m ping ansiblemaster
ansible -m setup webservers









======================================================================
docker ps -a --it will show all the exited and runnig containers
docker pull imagename
docker build -t nameof file . ----build a image with custom installations
docker exec -it containerid bash ----go into exicuted shell
docker ps
docker images
docker stop containerid
docker kill containerid-- it will kill the process immidiatly.but shows in exited status
docker rm containerid
docker rm -f containerid ---it cant show in exited state also
docker rmi imagename

docker commit containerid username r imagename
docker push username/imagename
docker login
Docker version 25.0.3
curl http://localhost:80 
docker tag containername newname
=================================================================================
what are the version installed in u r linux it will shows the list of java
update-alternatives --config java
to remove software from ubuntu
sudo apt-get purge openjdk-8-jdk
sudo apt-get remove --purge jenkins
sudo apt-get remove jenkins
sudo apt-get remove --auto-remove jenkins
sudo apt autoremove

======================================================================

if we want to install docker with userdata
#!/bin/bash
curl https://get.docker.com/ | bash
to exicute script we use bash hear
 
===============================================================

if you want to know which network is running in instance
ifconfig
if u want to see what host ports are running 
netstat -a | grep -i 8000 or 9000
ps -ef | grep apache ---what are the processes running it will shows u
dpkg -l | grep apache
===============================================================
cd -     -------it will move to past workplace where we worked. 
ls -lrt .git ----it will shows the list of files in .git folder
cat .git/head 
git is source code management sytem and version controlling system.
git init ----will create an empty repository.and it creates one hidden file ".git" file.
git config --global user.name "vinay"
git config --global --list ----what are the users already there that will shown here
git config --global user.email "vinayradham@gmail.com"
git remote add newgit link of github ------ we are giving link between local and remote and alias name to the link newgit
git remote -v ---- which u given for link that will be seen here
git push newgit master------ for pushing
git branch -----branches list
git branch vinay -----creating branch
git push newgit vinay ----local to remote pushing
git diff vinay --------master branch vinay branch madya files diffrence telsukodaniki we use this 
git merge vinay ----vinay branch master loki merge cheyyadaniki
git push newgit master 
git push newgit --all  -----anni branches files transfer cheyyadaniki we use this cmnd
git branch -d vinay ----delete branch in local
git push newgit :vinay  ----delete in remote github
git checkout vinay ----one branch to other branch
git reset -----to go back from stagging to untracked or working directory
git revert commitid ---- we want to delete one commit by using revert.back to new commit id with old data.we can move to 
old version 
git log ----to see the commit ids
git cherry-pick commit id --- we are having 2 files i want only one file to merge in master then we use git chery-pick
git reset --hard commitid ----moved to past commit.head moved to past commit what u need
git reflog --- to see the commit history unused commits bad commits all
git show commitid ---to see the difference of the commits 
git stash  ----to freeze some files after git add . it will works
git stash list ---to see how many files freezed
git stash apply ---to unstash the files
git stash drop
git stash -u

git stash pop
git tag tagname ---to compress a file.we cannot change after tagging
git push nani tag tagname ---to push a tag file into remote repo
git config --global --edit 
git commit --amend --reset-author
git log --graph --pretty=oneline
git merge creates new commit id.it creates history.it should track the history others will see this
git rebase doesnot create new commit id.it maintain cleaner history.in this pthers cannot see the history.
it shold not track the history
git rebase master 
====================================================================
jenkins:
gmail--click on photo--manage your google accounts----security--in search bar app passwords--add user--password generated ---copy that password.
goto jenkins--manage jenkins--system--email notification---smtpserver--smtp.gmail.com--goto adavanced--give user mail id --password is gmail app password--use ssl --smtp port 465--reply to address mailid 
--test once it is working or not if test passes mail sended to your given mail.if not it shows error.
goto job--configure--post build actions--email notification--add email..if build fails automatically send to your mail id.
--------
pipeline---1.git 2.shell script for maven 3.ssh agent for connect with node 4.deploy war ear in container 
manage jenkins--security---authorization--project based--add user--tick wt persmissions u want give --apply --save.
users-- create user--fill the details--create the user.
http://jenkinsip:8080/github-webhook/  -----adding url in github-repo-settings-webhooks-pasteurl-json format-save.it will give green right if the hook is applied 
scripted pipeline:
node{
    def mavenHome=tool name: "maven"
    stage('checkin code'){
        
        git 'https://github.com/nani0231/javaapp.git'
    }
    stage('build'){
        
        sh "${mavenHome}/bin/mvn clean package"
        
    }
    stage('sshagent,deploy war'){
        sshagent(['e022b5c8-ea90-46f5-ae3e-0579590c4ba1']) {
            sh "scp -o StrictHostKeyChecking=no target/java-web-app-1.0.war ubuntu@13.239.84.113:/opt/apache-tomcat-9.0.89/webapps/"
            }}   }
declerative:

pipeline{
agent any
tools{
   maven "maven" 
    
}
    stages{
        stage('code'){
            steps{
                git 'https://github.com/nani0231/maven-web-application.git'
            }
            
        }
        stage('build'){
            steps{
                sh "mvn clean package"
            }
            
        }
        stage('ssh,deployment'){
            steps{
                sshagent(['e022b5c8-ea90-46f5-ae3e-0579590c4ba1']) {
                    deploy adapters: [tomcat9(credentialsId: 'bf1dbf8a-ed76-4341-8b4a-a661a06b346b', path: '', url: 'http://52.64.78.12:8080/')], contextPath: '/bjp', war: '**/*.war'
                    
}}}}}

sh "scp -o StrictHostKeyChecking=no target/maven-web-application.war ec2-user@15.207.54.159:/opt/apache-tomcat-9.0.87/webapps/"
ssh agent --- plugin for creating username keypair to login and deploy into tomcat server
deploy to container ---plugin for deploying war/ear filr into server plugin 
maven integration --plugin for maven project building .under freestyle we are getting maven project icon
tomcat url-http:ip:8080
file path-**/*.war
context path-/giveanything
github-webhooks will be paste it into webhooks
/var/lib/jenkins/secrets/initialAdminPassword ----intial password for jenkins login path
systemctl status jenkins ---it will shows the status of jenkins
service jenkins status ----it is also for status check
manage jenkins--security ---agents--tcp port--random
manage jenkins--nodes-new node--add details and save---to download java in slave.to install jar file we are having some
 linux commands install in slave --slave comes into active mode.
usermod -aG docker jenkins
usermod -aG docker ubuntu
systemctl restart docker
if permission denied in jenkins for building an image?
ans: chmod 777 /var/run/docker.sock
give permission to the docker
if  u want to cp file from back folder to current folder?
ans:  sudo cp ../../../../../home/ubuntu/docker-flask-demo/Dockerfile .
If you want to see the permissions of the file?
ans:(long listing)ll /var/run/docker.sock
 webhooks-------1195a49cf35c8c39b09b0c4c2d171618cf
if we forgot the project username password
go to cli open /var/lib/jenkins/config.xml---change usersecurity true to false user will be deleted but job remain
if u want to see output /var/lib/jenkins/jobs/project/logs---we can see console output

=========================================================================
vs code --- ctrl+shift+p --code managed in correct manner
ctrl+space ---it show what is the possibilities to enter
=====================================================================
windows shortcuts
screenshot ----windoskey+printscreen
undo ----ctrl+z
sysdm.cpl --- to see advance-environmentvariable-edit-path ---in windows 

=====================================================================
kubernetes:

kops cluster creation:
1.we need to crete one domain name
2.we have one cloud account
3.we need to create s3 bucket& route 53 . in route53 we create one hosted zone.on that we are getting records.
that will be pasted in godaddy app.in go daddy app dns management on that nameservers we paste the name servers
 of route53 so that will be saved.if all over the world will come into the application through that nameservers.
4.create one management server or gem server which holds all the scripts and deployments
4.install kops binary (kops github,releases,linux 64 kops,latest beta version)/usr/local/bin/kops. chmod 700 kops
5.install kubectl (kubectl download) chmod 700 kubectl 
6.install aws-cli (awscli download) aws configure,create iam user ,add access key secret key
7.ssh-keygen for public and private keys . ll .ssh
8.kops cheatsheet 
kops create cluster \
--state=s3://vinayk8s.world \
--node-count=2 \
--master-size=t2.micro \
--node-size=t2.micro \
--zones=us-east-1a \
--name=vinayk8s.world  \
--dns-zone=vinayk8s.world \
--master-count 1 \
--node-volume-size 10 \
--master-volume-size 20 
--yes
kops get cluster --state=s3://vinayk8s.world ----it will show the details cluster 
----------------------kops delete cluster --state=s3://vinayk8s.world --name=vinayk8s.world --yes ------it will delte the cluster
kops get ig --state=s3://vinayk8s.world --name=vinayk8s.world -----it will show instance group datils
kops edit ig --state=s3://vinayk8s.world control-plane-us-east-1a --name=vinayk8s.world ---if u want to 
edit control plane details we can change here.
kops edit ig --state=s3://vinayk8s.world nodes-us-east-1a  --name=vinayk8s.world ---u can change nodes info here
kops update cluster --state=s3://vinayk8s.world --name=vinayk8s.world
if u want to see already installed data in kops then use "cat kopsdoc".it will show what configuration u have installed.
kops by sai sir:


Kubernetes on AWS using Kops
1. Launch Linux EC2 instance in AWS (Kubernetes Client)
2. Create and attach IAM role to EC2 Instance.
Kops need permissions to access
	S3
	EC2
	VPC
	Route53
	Autoscaling
	etc..
3. Install Kops on EC2
curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64
chmod +x kops-linux-amd64
sudo mv kops-linux-amd64 /usr/local/bin/kops

4. Install kubectl
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
5. Create S3 bucket in AWS
S3 bucket is used by kubernetes to persist cluster state, lets create s3 bucket using aws cli Note: Make sure you choose bucket name that is uniqe accross all aws accounts

aws s3 mb s3://project.in.k8s --region us-west-2
6. Create private hosted zone in AWS Route53
Head over to aws Route53 and create hostedzone
Choose name for example (sai.in)
Choose type as privated hosted zone for VPC
Select default vpc in the region you are setting up your cluster
Hit create
7 Configure environment variables.
Open .bashrc file

	vi ~/.bashrc
Add following content into .bashrc, you can choose any arbitary name for cluster and make sure buck name matches the one you created in previous step.

export KOPS_CLUSTER_NAME=project.in
export KOPS_STATE_STORE=s3://project.in.k8s
Then running command to reflect variables added to .bashrc

	source ~/.bashrc
8. Create ssh key pair
This keypair is used for ssh into kubernetes cluster

ssh-keygen
9. Create a Kubernetes cluster definition.
kops create cluster \
--state=${KOPS_STATE_STORE} \
--node-count=2 \
--master-size=t3.medium \
--node-size=t3.medium \
--zones=us-east-1b \
--name=${KOPS_CLUSTER_NAME} \
--dns public \
--master-count 1
10. Create kubernetes cluster
kops update cluster --yes --admin
Above command may take some time to create the required infrastructure resources on AWS. Execute the validate command to check its status and wait until the cluster becomes ready

kops validate cluster
For the above above command, you might see validation failed error initially when you create cluster and it is expected behaviour, you have to wait for some more time and check again.

11. To connect to the master
ssh admin@api.javahome.in
Destroy the kubernetes cluster
-------------------------------------------------------------------------------------kops delete cluster  --yes
Update Nodes and Master in the cluster
We can change numner of nodes and number of masters using following commands

   kops edit ig nodes change minSize and maxSize to 0
   kops get ig- to get master node name
   kops edit ig - change min and max size to 0
   kops update cluster --yes 
sai sir eks cluster:
kubectl install use in browser
paste kubectl commands
then eksctl commands
eksctl installed 
eksctl create cluster \
--nodes 3 \
--node-type t3.medium \
--region us-east-2 \
--name new-cluster
open eks service on aws new cluster is creating it takes 20 mints time
in eks managed k8s only slaves count shown and pay for slaves
master is managed by aws cloud only
master machines dont take load on themselves.they just distribute the load to the slave machines
cluster is in active status
in ec2 dashboard slaves or creating so wait for 10mints
we need to intsall one athenticater plugin.this plugin helps you to access on eks.
aws iam authenticator plugin installation after we use kubectl get nodes


eksctl delete cluster --name my-cluster --region region-code
--k8s works on past 2 versions and present version patches only.if it is in 1.18.0 version.n-2 version means it will work on past 17,16 patches and updates
kubernetes commands:
kubectl get nodes
kubectl get pods
kubectl get ns
if u want to see another name space pods:
kubectl get pods -n namespacename
kubectl cluster-info ---shows the cluster info
kops get clusters
kops get cluster clustername -o yaml
ctrl+shift+p ---format purpose yaml code
if u dont give any network it will take "kubenet" automatically in kops.kubenet allows only 50 entries or 50 nodes
if u take any network like calico it will take calico network.if u have database pod it will communicate with only some pods on that time we use 3rd party plugins like calico.
alias ku='kubectl'---to use shortcut for kubectl.if u want to put it in .bashrc u can run daily
ku get pods -A --all namespaces pods will shown here.
kubectl describe node ipofnode--it will show detailes of that node
kubectl label node ip-of-node node-role.kubernetes.io/worker=worker1 ---it will add the name to node
kubectl label node ip-of-node node-role.kubernetes.io/worker-   -----it will remove node name
cat .kube/config ----details of cluster will shown here
ku run test --image=nginx ---to create a pod r microservice 
kubectl get pods -o yaml
kubectl exec -it demo ls /etc
kubectl exec -it demo -- df -h
kubectl expose pod demo --port=8000 --target-port=80 ---expose the pod internally
kubectl get service
curl http://100.69.106.153:8000
kubectl expose pod demo --port=8000 --target-port=80 --type=NodePort
ku get svc ---shows the services and port details to connect externally .
ku delete svc testpodn
ku describe svc testpod
ku drain node-ip --force --ignore-daemonsets ---before delete a node we use this command.with this command pods will moved to another node and then we use "ku delete node nodename".
ku describe pod podname
ku port-forward pod/podname 8888:80 ----forward port id for testing purpose
curl http://localhost:8888 ---take duplicate and test once. 
ku get pods -o yaml
ku get pod podname -o yaml
ping www.google.com
ping ipaddress
pods will commuincate with each other with ipaddress every pod having one ip.if u want to discommunicate pods we use network policys.calico.pod security policys.
kubectl exec -it podname -- ls -la
kubectl exec -it podname -- bash ---go into pod 
ctrl p+q --to come out
ku create namespace ns1 ---creating namespace
ku get pods -n namespacename
ku get pod -n namespacename podname
ku describe pod -n namespacename podname
ku exec -it podname -n namespacename --bash 
ku describe pod podname -n namespacename
bash b1-k8s-script.sh
ctrl+o ctrl+x
ku delete pod podname
ku delete -f pod.yml
ku get pod podname --show-labels
ku get pods -l env=prod ------key=value what we give in labels.that pod will shows
ku label pod podname key=value ----adding a label to pod.but yaml file not updated but pod is updated with this.but better to add in yaml file.give apply command
ku label pod podname key-    -------delete the label.
ku annotate pod podname data=vinay ---key=value adding an annotation to pod
ku delete pod -l env=prod ----delete the label 
ku get pods --show-labels ---
ku describe svc svcname
ku logs podname
labels:is used for decision making,sorting,deleting 
annotations:used for version numbers text we use.it not used for deciosion making
kubectl create is used to create a new resource.but we cannot configure with it
kubectl apply is used for create and configure.if u want to add data on already created resource we use apply command.updating purpose 

crashloopbackoff:if we are having any error inside the image it will restart automatically up the pod.but we have solve the error if we dont.
it willrestart evary time.when ever we create 3 containers in 1 pod.ram is insufficient msg comes and crashloopbackoff error will come.
so we increse the limts or remove container then pod will work properly
---we are having 2 namespaces and 2 pods in each namespace. but are communicate each other.for this we use calico network policy

pods:we can create multiple container in one pod.on that one container acts as a main container and another one acts as a sub container.
one container recieve the files and stored in volume.processed from another container.web container data copied into another container r processing we use multiple containers.in some times backend work like 
logs copping done by sub container.main container acts as a web container.

imagepullbackoff error:it will come where image is not there to pull from dockerhub r ecr,
or if the image is pulling access denied bcz that image in privatemode for creating pod by using run command
ku edit pod podname ---we can edit that imagepullbackoff by using this command.after we change the image it will comes into runnig mode

CNI: container network interface(calico).it is mainly used for pod to pod communication,container to container communication,
pod to service communication,service to external communication.is depend on cni.
calico for network policy enforcement:by default pods contact with other pods .to apply some permissions 
and rules we use this calico.it will establish network b/w the pods

target port---container level opening port--80
port ----host level opening port--8000 r something
---
apiVersion: v1 ---library
kind: Pod ---
metadata:
  name: tomcat-pod1 ---pod name
  labels:       -----with the help of label we can access another service
    env: tomgirl
    owner: vinay
spec:
  containers:   ---- container details
    - name: tomee1
      image: httpd


---
service
apiVersion: v1
kind: Service
metadata:
  name: myservice ---service name
spec:
  type: NodePort ----to expose outside cluster
  selector:
    env: tomgirl ----to access labels in pod will given in selector
  ports:
    - port: 8000 -----host port
      targetPort: 80  ---container port
...





kubeproxy:it will open pods iptable,ports outside the cluster




 
quorum-to maintaintain minimum no of servers to run a microservices--1,3,5,7,9--7/2=3.5=4 minimum